# Backpressure & Queueing Theory

비동기 시스템에서 소비 속도가 생산 속도를 따라가지 못하면 큐가 폭발한다. Backpressure와 Queueing을 이해하면 이런 상황을 예측하고 제어할 수 있다.

---

## 1. Queueing Theory 기초
- **Little's Law**: `L = λ × W` (큐에 쌓인 평균 작업 수 = 도착률 × 평균 대기 시간).
- **도착률(λ)** vs **처리률(μ)**: λ가 μ보다 크면 큐 길이가 무한히 증가한다.
- **서비스 시간 분포**: 작업 시간이 고르지 않을수록(높은 분산) 지연이 커진다.

---

## 2. Backpressure란?
- 다운스트림(소비자)이 처리 가능한 만큼만 업스트림(생산자)이 데이터를 보내도록 제어하는 메커니즘.
- Reactive Streams, gRPC Flow Control, Netty/Node.js 등에서 지원.
- 구현 방식: 토큰 버킷, 크레딧 기반 흐름 제어, 큐 길이 모니터링 후 throttle.

---

## 3. 설계 전략
1. **큐 길이 모니터링**: 임계치 초과 시 경고, API 응답 지연, Throttle.
2. **버퍼 분리**: 각 서비스마다 큐를 분리해 특정 장애가 전체로 전파되지 않도록.
3. **우선순위 큐**: 긴급 작업과 일반 작업을 분리.
4. **드롭/리트라이 정책**: 처리 불가 시 일정 비율을 드롭하거나 DLQ로 이동.

---

## 4. 체크리스트
- [ ] 생산자/소비자 각각의 처리량(λ, μ)을 측정하고 있는가?
- [ ] 큐 길이, 대기 시간, 재시도 횟수 등 지표에 임계치를 설정했는가?
- [ ] Backpressure가 작동하지 않을 때의 Fail-safe(드롭, 오프로드)를 정의했는가?
- [ ] 토큰 버킷/크레딧/슬라이딩 윈도우 등 속도 제어 방식을 문서화했는가?

---

## 5. 학습/실습 아이디어
- **실습 1**: 메시지 큐(Kafka/RabbitMQ)에서 소비자 속도를 줄여 큐가 폭증하는 상황을 만들어보고 지표를 수집한다.
- **실습 2**: Reactor, RxJava, Kotlin Flow 등에서 request(n) 기반 Backpressure를 코드로 구현해 본다.
- **실습 3**: 토큰 버킷 알고리즘을 직접 구현해 요청 속도를 제한하고 모니터링한다.

